{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# Artififial Intelligence - COMPSCI4004 & COMPSCI5087 2019-2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## Lab Week 2: Introduction - PEAS and the Open AI Gym environment\n",
    "<font size=1>v2019-2020a</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objectives:\n",
    "- Familiarise yourself with Open AI Gym and get the Python package installed on your account/computer.\n",
    "- Obtain an understanding of the Open AI Gym by inspecting the documentation and running a basic tutorial.\n",
    "- Analyse a specific problem using the PEAS framework to identify the performance measure, environment (including a task description), sensors and actuators."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Guide**: The notebook contains specific tasks you'll need to carry out to make the notebook run. These are indicated with:\n",
    "\n",
    "* <font color=dark-magenta>TASK:</font> This is a task for you to carry out before proceeding. \n",
    "* <font color=green>CHECKPOINTS:</font> This indicates a key point you should understand before proceeding. If you're in soubt then ask then consult the lab assistants.\n",
    "* A basic model solution (marked with <font color=red>Solution</font>) will be provided a week after the Lab session."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Q2.1 Prerequisites\n",
    "- <font color=dark-magenta>TASK:</font> Before installing the Open AI Gym environment make sure you have a Python 3.6+ environment installed on your computer.\n",
    "\n",
    " - Lab machines: Python 3.7 is installed (find Anaconda promt via the start menu)\n",
    " - Own Linux or Windows: We recommend installing [Anaconda](https://www.anaconda.com/download/) (Python 3.6+) which includes numpy and other useful libraries that you would otherwise have to install yourself.\n",
    " - Own MacOS: We generally recommend using the already installed Python and simply updating the packages as needed.\n",
    "\n",
    "\n",
    "*Warning*: We only support the the Lab machines (Windows) and it is your own responsibility if you want to install the environemnt on your own setup."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Q2.2: Installing Open AI Gym...\n",
    "- <font color=dark-magenta>TASK:</font> Install the Pyhton-based Open AI Gym. An installation guide can be found at https://gym.openai.com/docs/ (avoid building from source if possible). \n",
    "    - On the lab machines: Run \"pip install --user gym[atari]\" from an Anaconda prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Q2.3: Complete the Open Gym Tutorial - the Cartpole environment\n",
    "- <font color=dark-magenta>TASK:</font> Step through the CartPole tutorial and run the code included in the cell below (from the tutorial). The tutorial is based on the CartPole example and we recommend reading the problem [description](https://gym.openai.com/envs/CartPole-v1/) and inspecting the environment definition (Python code; available via [github](https://github.com/openai/gym/blob/master/gym/envs/classic_control/cartpole.py))\n",
    " - Note: Depending on your programming background you may find it useful using standard Python (i.e., command line or an IDE, e.g. [PyCharm](https://www.jetbrains.com/pycharm/) or [vscode](https://code.visualstudio.com/)) when programming against the Open AI gym."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "env = gym.make('CartPole-v0')\n",
    "env.reset()\n",
    "\n",
    "for step in range(200):\n",
    "    env.render()\n",
    "    action = env.action_space.sample() # take random action\n",
    "    observation, reward, done, info = env.step(action) \n",
    "        \n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- <font color=green>CHECKPOINT:</font> You should see a new window open up and a cartpole starting to move around. You may see a warning because the CartPole keeps moving even though it has reached its goal. If that is the case, then you're safe to move on!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Q2.4: PEAS Analysis of The Frozen Lake Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part, we will analyse the Frozen Lake enviroment from the Open AI Gym. The goal is to make a PEAS analysis of this environment. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q2.4.1: Frozen Lake"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- <font color=dark-magenta>TASK: </font> Explore the [Frozen Lake environment](https://gym.openai.com/envs/FrozenLake-v0/) in the Open AI Gym and make sure to inspect the [source code](https://github.com/openai/gym/blob/master/gym/envs/toy_text/frozen_lake.py). Make an initial  analysis of the Task Environment by identifying the states, actions and rewards in this environment. Executing the code below may help you appreciate how the environment is represented in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------\n",
      "\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "\n",
      "--------------------------------\n",
      "\n",
      "Observation/states: Discrete(16)\n",
      "Action space: Discrete(4)\n",
      "Rewards: (0, 1)\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "env = gym.make('FrozenLake-v0')\n",
    "\n",
    "print(\"--------------------------------\") \n",
    "env.render()\n",
    "print(\"\\n--------------------------------\\n\")\n",
    "\n",
    "print(\"Observation/states: %s\" % (env.observation_space))\n",
    "print(\"Action space: %s\" % (env.action_space))\n",
    "print(\"Rewards: \" + str(env.reward_range))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q2.4.2: Implement an agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- <font color=dark-magenta>TASK: </font>  Implement an agent that takes random actions for the Frozen lake environment (simliar to the CartPole example). \n",
    "Your agent should display:\n",
    " * a rendering of the environment (use 'env.render()' for this)\n",
    " * the observation/state (a coordinate or similar)\n",
    " * the action\n",
    " * the reward obtained\n",
    " * an indication if the agent has succeeded (env.step() usually returns this information)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INSERT YOUR CODE HERE]\n"
     ]
    }
   ],
   "source": [
    "print(\"[INSERT YOUR CODE HERE]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- <font color=green>CHECKPOINT: </font> Rerun you agent a couple of times and observe the percept and action sequences to make sure it performans as expected.... Hint: is the environment deterministic or stochastic?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q2.4.3: Full PEAS Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- <font color=dark-magenta>TASK: </font> Perform a full PEAS analysis (see the AIMA book chapter 2, or the lecture slides from week 2) to identify the\n",
    "    \n",
    "    - Performance measure \n",
    "    - Environment (including a full description of the environment)\n",
    "    - Actuators (which actions can the agent take) ?\n",
    "    - Sensors, i.e., what sensory input/observations are available to the agent (in the current Open AI Gym environment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
