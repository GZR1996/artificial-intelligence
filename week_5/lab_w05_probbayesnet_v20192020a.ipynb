{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Artificial Intelligence - COMPSCI4004/5089 2019-2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab Week 5: Probability and Bayesian Networks <small><small><small>v20192020a</small></small></small>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Aim**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Get hands-on experience with discrete random variables, probabilities and distributions (in Python)\n",
    "* Formulate and implement a Bayesian network\n",
    "* Apply basic inference methods in the network\n",
    "\n",
    "**Guide**:\n",
    "\n",
    "The notebook has two parts:\n",
    "\n",
    "   - Part I (Q5.0-Q5.3): Basic probability and inference (in Python and on paper) \n",
    "   - Part II (Q5.4): BayesNet   \n",
    "   - We also encourge you to work the quiz during the Lab session.  \n",
    "   \n",
    "\n",
    "Each part contains specific tasks - often open-ended questions - that you'll need to carry out to make the notebook run or be able to undersatnd the next steps. These are indicated with:\n",
    "\n",
    "* <font color=dark-magenta>TASK:</font> This is a task for you to carry out before proceeding. \n",
    "* <font color=green>CHECKPOINTS:</font> This indicates a key point you should understand before proceeding. If you're in doubt then ask then consult the lab assistants.\n",
    "* A basic model solution (marked with <font color=red>SOLUTION</font>) will be provided a week after the Lab session.\n",
    "\n",
    "<br>\n",
    "\n",
    "<b><font color=red>Note: </font>We expect that it will take most students 3-4h to compelte this notebook; but don't worry there will also be time to work on it in next week's Lab sesson (1h)</b>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q5.0 Introduction & Housekeeping "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise we will examine discrete random variables and discrete distributions (i.e., distributions which are easy to enumerate and relate to) and we will implement a Bayesian/belief network in Python.\n",
    "\n",
    "The exercise relies on the [AIMA toolbox](https://github.com/aimacode/aima-python), Python 3 (download it from Moodle not github!) - and is adapted from the `probability.ipynb` tutorial found in the AIMA toolbox. Note: the relevant files from the AIMA toolbox are provided with in the lab 4 zip file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Prerequisites__\n",
    "\n",
    "Importing these modules from the provided AIMA module should run without error. If you get an error you probably need to update your Python installation.\n",
    "\n",
    "* <font color=dark-magenta>TASK:</font> Remember to change the AIMA_TOOLBOX_ROOT variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "AIMA_TOOLBOX_ROOT=\"D:/project/python/aima-python-uofg_v20192020b\"\n",
    "sys.path.append(AIMA_TOOLBOX_ROOT)\n",
    "\n",
    "from aimautils import (\n",
    "    product, argmax, element_wise_product, matrix_multiplication,\n",
    "    vector_to_diagonal, vector_add, scalar_vector_product, inverse_matrix,\n",
    "    weighted_sample_with_replacement, probability, isclose, normalize\n",
    ")\n",
    "import random\n",
    "from collections import defaultdict\n",
    "\n",
    "# A specific helper function (no need to understand at this point!)\n",
    "def extend(s, var, val):\n",
    "    \"Copy the substitution s and extend it by setting var to val; return copy.\"\n",
    "    s2 = s.copy()\n",
    "    s2[var] = val\n",
    "    return s2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q5.1 The basics - probability distributions in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part, we will examine a basic class for defining probability distributions over discrete random variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q5.1.1 Variables and distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <font color=dark-magenta>TASK:</font> Whats is a discrete random variable?\n",
    "* <font color=dark-magenta>TASK:</font> What is a probability distribution over a random variable?\n",
    "\n",
    "---\n",
    "\n",
    "#### Q5.1.2 Variables and distributions in Python\n",
    "* <font color=dark-magenta>TASK:</font> Skim though the `ProbDist` code below and make sure you understand how the distributions and events are specified. \n",
    "___Hint___: We use a class to make it easier to do inference late ron but you could also implement a lot of this functionality using e.g.  of this in a basic numpy array\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The class `ProbDist` defines a discrete probability distribution. We name our random variable and then assign probabilities to the different values of the random variable. Assigning probabilities to the values works similar to that of using a dictionary with keys being the Value and we assign to it the probability.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "class ProbDist:\n",
    "    \"\"\"A discrete probability distribution. You name the random variable\n",
    "    in the constructor, then assign and query probability of values.\n",
    "    >>> P = ProbDist('Flip'); P['H'], P['T'] = 0.25, 0.75; P['H']\n",
    "    0.25\n",
    "    >>> P = ProbDist('X', {'lo': 125, 'med': 375, 'hi': 500})\n",
    "    >>> P['lo'], P['med'], P['hi']\n",
    "    (0.125, 0.375, 0.5)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, varname='?', freqs=None):\n",
    "        \"\"\"If freqs is given, it is a dictionary of values - frequency pairs,\n",
    "        then ProbDist is normalized.\"\"\"\n",
    "        self.prob = {}\n",
    "        self.varname = varname\n",
    "        self.values = []\n",
    "        if freqs:\n",
    "            for (v, p) in freqs.items():\n",
    "                self[v] = p\n",
    "            self.normalize()\n",
    "\n",
    "    def __getitem__(self, val):\n",
    "        \"\"\"Given a value, return P(value).\"\"\"\n",
    "        try:\n",
    "            return self.prob[val]\n",
    "        except KeyError:\n",
    "            return 0\n",
    "\n",
    "    def __setitem__(self, val, p):\n",
    "        \"\"\"Set P(val) = p.\"\"\"\n",
    "        if val not in self.values:\n",
    "            self.values.append(val)\n",
    "        self.prob[val] = p\n",
    "\n",
    "    def normalize(self):\n",
    "        \"\"\"Make sure the probabilities of all values sum to 1.\n",
    "        Returns the normalized distribution.\n",
    "        Raises a ZeroDivisionError if the sum of the values is 0.\"\"\"\n",
    "        total = sum(self.prob.values())\n",
    "        if not isclose(total, 1.0):\n",
    "            for val in self.prob:\n",
    "                self.prob[val] /= total\n",
    "        return self\n",
    "\n",
    "    def show_approx(self, numfmt='{:.3g}'):\n",
    "        \"\"\"Show the probabilities rounded and sorted by key, for the\n",
    "        sake of portable doctests.\"\"\"\n",
    "        return ', '.join([('{}: ' + numfmt).format(v, p)\n",
    "                          for (v, p) in sorted(self.prob.items())])\n",
    "\n",
    "    def __repr__(self):\n",
    "        return \"P({})\".format(self.varname)\n",
    "    \n",
    "\n",
    "def event_values(event, variables):\n",
    "    u\"\"\"Return a tuple of the values of variables in event.\n",
    "    >>> event_values ({'A': 10, 'B': 9, 'C': 8}, ['C', 'A'])\n",
    "    (8, 10)\n",
    "    >>> event_values ((1, 2), ['C', 'A'])\n",
    "    (1, 2)\n",
    "    \"\"\"\n",
    "    if isinstance(event, tuple) and len(event) == len(variables):\n",
    "        return event\n",
    "    else:\n",
    "        return tuple([event[var] for var in variables])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "#### Q5.1.3 Example: The unfair coin\n",
    "\n",
    "Consider an unfair coin which has 75% probability of coming out tail. Lets define the probability distribution for Flip, i.e. P(Flip).\n",
    "\n",
    "* <font color=dark-magenta>TASK:</font> Step through/run the code below and make sure you appreciate how the ProbDist object can be used.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "'P(Flip)'"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 13
    }
   ],
   "source": [
    "p = ProbDist('Flip')\n",
    "p['H'], p['T'] = 0.25, 0.75\n",
    "p['T']\n",
    "\n",
    "repr(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first parameter of the constructor **varname** has a default value of '?'. So if the name is not passed it defaults to ?. The keyword argument **freqs** can be a dictionary of values of random variable:probability. These are then normalized such that the probability values sum upto 1 using the **normalize** method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "'?'"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 15
    }
   ],
   "source": [
    "p = ProbDist(freqs={'low': 125, 'medium': 375, 'high': 500})\n",
    "p.varname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(0.125, 0.375, 0.5)"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 16
    }
   ],
   "source": [
    "(p['low'], p['medium'], p['high'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Besides the **prob** and **varname** the object also separately keeps track of all the values of the distribution in a list called **values**. Every time a new value is assigned a probability it is appended to this list, This is done inside the **_ _setitem_ _** method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "['low', 'medium', 'high']"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 17
    }
   ],
   "source": [
    "p.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### Q5.1.4 Example - Counting Animals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distribution by default is not normalized if values are added incremently. We can still force normalization by invoking the **normalize** method. This is relevant when we e.g. count events happing in the world. For example imagine counting the occurances of Mice, Dog and Cat on a farm and then wanting to quantify the probability of seeing each of these animals on the farm.\n",
    "\n",
    "\n",
    "* <font color=dark-magenta>TASK:</font> Step through/run the code below and make sure you appreciate how the ProbDist object can be used in bith an unnormalized and normalized form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(50, 114, 64)"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 18
    }
   ],
   "source": [
    "p = ProbDist('Y')\n",
    "p['Cat'] = 50\n",
    "p['Dog'] = 114\n",
    "p['Mice'] = 64\n",
    "(p['Cat'], p['Dog'], p['Mice'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(0.21929824561403508, 0.5, 0.2807017543859649)"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 19
    }
   ],
   "source": [
    "p.normalize()\n",
    "(p['Cat'], p['Dog'], p['Mice'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is also possible to display the approximate values upto decimals using the **show_approx** method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "'Cat: 0.219, Dog: 0.5, Mice: 0.281'"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 20
    }
   ],
   "source": [
    "p.show_approx()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q5.2 Joint Probability Distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part, we will define a basic Python class for a JOINT probability distributions over __discrete__ random variables, e.g. $P(X,Y)$ where X can be true or false. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q5.2.1 Basic joint distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <font color=dark-magenta>TASK:</font> Write down (on paper or in this notebook) the two possible variations of the product-rule for the joint distrbution  $P(X,Y)$ ?\n",
    "* <font color=dark-magenta>TASK:</font> Write down (on paper or in this notebook) the marginalization / sum-rule for $P(X,Y)$ (marginalizing over Y) ? \n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "+ product rule: P(X, Y) = P(X|Y)P(Y) = P(Y|X)P(X)\n",
    "- marginalization / sum-rule: P(X_i) = sum(P(X_i|Y_i)P(Y_i))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q5.2.2 Events\n",
    "\n",
    "The helper function **event_values** returns a tuple of the values of variables in event. An event is specified by a dict where the keys are the names of variables and the corresponding values are the value of the variable. Variables are specified with a list. The ordering of the returned tuple is same as those of the variables.\n",
    "\n",
    "\n",
    "Alternatively if the event is specified by a list or tuple of equal length of the variables. Then the events tuple is returned as it is.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(8, 10)"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 22
    }
   ],
   "source": [
    "event = {'A': 10, 'B': 9, 'C': 8}\n",
    "variables = ['C', 'A']\n",
    "event_values(event, variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Q5.2.3  Joint distribution class\n",
    "\n",
    "_A probability model is completely determined by the joint distribution for all of the random variables._ (**AIMA Section 13.3**) The function below implements the class **JointProbDist** which inherits from the **ProbDist** class. This class specifies a discrete probability distribute over a set of variables (e.g. X and Y). \n",
    "\n",
    "* <font color=dark-magenta>TASK:</font> Skim though the `JointProbDist` code below and make sure you understand how the distributions and events are specified. \n",
    "___Hint___: We use a class to make it easier to do inference later on but you could also implement a lot of this functionality using e.g.  of this in a basic numpy array. I tis not critical that you undersatnd all aspects of the code but simply accept that it holds the $P(X,Y,...)$-values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "class JointProbDist(ProbDist):\n",
    "    \"\"\"A discrete probability distribute over a set of variables.\n",
    "    >>> P = JointProbDist(['X', 'Y']); P[1, 1] = 0.25\n",
    "    >>> P[1, 1]\n",
    "    0.25\n",
    "    >>> P[dict(X=0, Y=1)] = 0.5\n",
    "    >>> P[dict(X=0, Y=1)]\n",
    "    0.5\"\"\"\n",
    "\n",
    "    def __init__(self, variables):\n",
    "        self.prob = {}\n",
    "        self.variables = variables\n",
    "        self.vals = defaultdict(list)\n",
    "\n",
    "    def __getitem__(self, values):\n",
    "        \"\"\"Given a tuple or dict of values, return P(values).\"\"\"\n",
    "        values = event_values(values, self.variables)\n",
    "        return ProbDist.__getitem__(self, values)\n",
    "\n",
    "    def __setitem__(self, values, p):\n",
    "        \"\"\"Set P(values) = p.  Values can be a tuple or a dict; it must\n",
    "        have a value for each of the variables in the joint. Also keep track\n",
    "        of the values we have seen so far for each variable.\"\"\"\n",
    "        values = event_values(values, self.variables)\n",
    "        self.prob[values] = p\n",
    "        for var, val in zip(self.variables, values):\n",
    "            if val not in self.vals[var]:\n",
    "                self.vals[var].append(val)\n",
    "\n",
    "    def values(self, var):\n",
    "        \"\"\"Return the set of possible values for a variable.\"\"\"\n",
    "        return self.vals[var]\n",
    "\n",
    "    def __repr__(self):\n",
    "        return \"P({})\".format(self.variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Values for a Joint Distribution is a an ordered tuple in which each item corresponds to the value associate with a particular variable. For Joint Distribution of X, Y where X, Y take integer values this can be something like (18, 19)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q5.2.2 Example\n",
    "\n",
    "* <font color=dark-magenta>TASK:</font> Step through/run the example code below and make sure you appreciate how the JointProbDist object can be used in defining a joint probability distrbution.\n",
    "\n",
    "To specify a Joint distribution we first need an ordered list of variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "111\n"
     ],
     "output_type": "stream"
    },
    {
     "data": {
      "text/plain": "P(['X', 'Y'])"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 33
    }
   ],
   "source": [
    "variables = ['X', 'Y']\n",
    "P_XY = JointProbDist(variables)\n",
    "P_XY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like the **ProbDist** class **JointProbDist** also employes magic methods to assign probability to different values.\n",
    "The probability can be assigned in either of the two formats for all possible values of the distribution. The **event_values** call inside  **_ _getitem_ _**  and **_ _setitem_ _** does the required processing to make this work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "asda\nasda\ns\ns\n"
     ],
     "output_type": "stream"
    },
    {
     "data": {
      "text/plain": "(0.2, 0.5)"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 35
    }
   ],
   "source": [
    "P_XY[1,1] = 0.2\n",
    "P_XY[dict(X=0, Y=1)] = 0.5\n",
    "\n",
    "(P_XY[1,1], P_XY[0,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is also possible to list all the values for a particular variable using the **values** method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "[1, 0, 2]"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 41
    }
   ],
   "source": [
    "P_XY[2, 2] = 0.2\n",
    "P_XY.values('X')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q5.2.2 Define a joint distrbution for the three variables X,Y,Z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <font color=dark-magenta>TASK:</font> Define a joint distrbution for the three variables X,Y,Z using the `JointProbDist`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "P(['X', 'Y', 'Z'])\n[0]\n[0, 1]\n[0, 2]\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# Insert your code here\n",
    "variables = ['X', 'Y', 'Z']\n",
    "P_XYZ = JointProbDist(variables)\n",
    "P_XYZ[0, 0, 0] = 0.1\n",
    "P_XYZ[0, 1, 2] = 0.3\n",
    "print(P_XYZ)\n",
    "print(P_XYZ.values('X'))\n",
    "print(P_XYZ.values('Y'))\n",
    "print(P_XYZ.values('Z'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q5.3  Inference Using Full Joint Distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we use the full Joint Distributions to calculate the posterior distribution given some evidence, i.e. an actual observation of the value of one or mode variable (e.g. X=true). \n",
    "\n",
    "We represent evidence by using a python dictionary with variables as dict keys and dict values representing the values.\n",
    "\n",
    "This is illustrated in **AIMA Section 13.3** of the book. The functions **enumerate_joint** and **enumerate_joint_ask** implement this functionality. Under the hood they implement **Equation 13.9** from the AIMA book.\n",
    "\n",
    "$${P}(X | {e}) = \\alpha {P}(X, {e}) = \\alpha {P}({e}|X)P(X) = α \\sum_{y} {P}(X, {e}, {y})\\,\\,\\,\\,\\,\\, Eq.\\,(1)$$\n",
    "\n",
    "Here $\\alpha$ is the normalizing factor. $X$ is our query variable and $e$ is the evidence (i.e. one or more condition variables). According to the equation we enumerate on the remaining variables $y$ (not in evidence or query variable) i.e. all possible combinations of $y$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q5.3.1 Normalizing constant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <font color=dark-magenta>TASK:</font> Determine $\\alpha$ in Eq (1) (hint use the product rule)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "#### Q5.3.2 Dentist Example\n",
    "We will be using the same \"dentist\" example as the book and lecture, i.e., let us create the full joint distribution from **Figure 13.3**.\n",
    "\n",
    "* <font color=dark-magenta>TASK:</font> Complete the specificaiton below and validate (manually) that the formulation constitutes a proper joint distrbution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_joint = JointProbDist(['Cavity', 'Toothache', 'Catch'])\n",
    "full_joint[dict(Cavity=True, Toothache=True, Catch=True)] = 0.108\n",
    "full_joint[dict(Cavity=True, Toothache=True, Catch=False)] = 0.012\n",
    "full_joint[dict(Cavity=True, Toothache=False, Catch=True)] = 0.016\n",
    "full_joint[dict(Cavity=True, Toothache=False, Catch=False)] = 0.064\n",
    "# Insert your code (four lines missing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q5.3.3 Computing marginal distrbutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <font color=dark-magenta>TASK:</font> Remind yourself of the the marginalisation rule/sum rule for joint distributions and outline how we can we manually find p(cavity) from the joint distribution $P(Cavity, Toothache, Catch)$)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q5.3.4 Computing marginal distrbutions in our `JointProb` class \n",
    "\n",
    "Let us now look at the **enumerate_joint** function returns the sum of those entries in $P$ consistent with $e$,provided variables is $P$'s remaining variables (the ones not in $e$). Here, $P$ refers to the full joint distribution. The function uses a recursive call in its implementation. The first parameter **variables** refers to remaining variables. The function in each recursive call keeps on variable constant while varying others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enumerate_joint(variables, e, P):\n",
    "    \"\"\"Return the sum of those entries in P consistent with e,\n",
    "    provided variables is P's remaining variables (the ones not in e).\"\"\"\n",
    "    if not variables:\n",
    "        return P[e]\n",
    "    Y, rest = variables[0], variables[1:]\n",
    "    return sum([enumerate_joint(rest, extend(e, Y, y), P)\n",
    "                for y in P.values(Y)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us assume we want to find **P(Toothache=True)**. This can be obtained by marginalization (**AIMA Equation 13.6**). We can use **enumerate_joint** to solve for this by taking Toothache=True as our evidence. **enumerate_joint** will return the sum of probabilities consistent with evidence i.e. the Marginal Probability (or distrbution)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "evidence = dict(Toothache=True) \n",
    "variables = ['Cavity', 'Catch'] # variables not part of evidence\n",
    "P_toothache = enumerate_joint(variables, evidence, full_joint)\n",
    "print(\"P(Toothache=True)=\" +str(P_toothache))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: we use the lower case notation `P_toothache` to indicate a true outcome of the Toothache random variable. We suggest using `P_nottoothache` to denote Toothache=False."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <font color=dark-magenta>TASK:</font> Manually verify this results (hint: see the lecture notes)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q5.3.5 More complicated marginals\n",
    " We can use the same function to find more complex probabilities like **P(Cavity=True and Toothache=True)** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evidence = dict(Cavity=True, Toothache=True)\n",
    "variables = ['Catch'] # variables not part of evidence\n",
    "P_toothachecavity = enumerate_joint(variables, evidence, full_joint)\n",
    "print(\"P(Toothache=True,Cavity=True)=\" +str(P_toothachecavity))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <font color=dark-magenta>TASK:</font> Manually verify this result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### Q5.3.6 Conditional marginals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Being able to sum over probabilities satisfying given evidence allows us to compute conditional probabilities like **P(Cavity=True | Toothache=True)  ** as we can rewrite this as \n",
    "\n",
    "$$P(Cavity=True\\, |\\, Toothache = True) = \\frac{P(Cavity=True \\, , \\, Toothache=True)}{P(Toothache=True)}\\, \\, \\, \\, Eq. (2)$$\n",
    "\n",
    "We have already calculated both the numerator and denominator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "P_cavity_toothache = P_toothachecavity/P_toothache\n",
    "print(\"P(Cavity=True | Toothache=True )=\" +str(P_cavity_toothache))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <font color=dark-magenta>TASK:</font> Manually verify this result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q5.3.7 Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Rewrite Eq (2) into the standard form of Bayes rule, i.e. $P(A|B)=P(B|A)P(A)/(B)$, (insert latex here or do it on paper). Hint: this is almost trivial if you know the product rule."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q5.3.8 Implementing Bayes rule in Python via `enumerate_joint_ask`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the standard form of Bayes rule we are interested in the probability distribution of a particular variable conditioned on some evidence, e.g. $P(Toothache = True\\, |\\, Cavity=True)$. This can involve doing calculations like above for each possible value of the variable. This has been implemented slightly differently  using normalization in the function **enumerate_joint_ask** which returns a probability distribution over the values of the variable $X$, given the {var:val} observations **e**, in the **JointProbDist P**. The implementation of this function calls **enumerate_joint** for each value of the query variable and passes **extended evidence** with the new evidence having $X=x_i$. This is followed by normalization of the obtained distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enumerate_joint_ask(X, e, P):\n",
    "    \"\"\"Return a probability distribution over the values of the variable X,\n",
    "    given the {var:val} observations e, in the JointProbDist P. [Section 13.3]\n",
    "    >>> P = JointProbDist(['X', 'Y'])\n",
    "    >>> P[0,0] = 0.25; P[0,1] = 0.5; P[1,1] = P[2,1] = 0.125\n",
    "    >>> enumerate_joint_ask('X', dict(Y=1), P).show_approx()\n",
    "    '0: 0.667, 1: 0.167, 2: 0.167'\n",
    "    \"\"\"\n",
    "    assert X not in e, u\"Query variable must be distinct from evidence\"\n",
    "    Q = ProbDist(X)  # probability distribution for X, initially empty\n",
    "    Y = [v for v in P.variables if v != X and v not in e]  # hidden variables.\n",
    "    for xi in P.values(X):\n",
    "        Q[xi] = enumerate_joint(Y, extend(e, X, xi), P)\n",
    "    return Q.normalize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us find $P(Cavity | Toothache=True)$ using **enumerate_joint_ask** ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_variable = 'Cavity'\n",
    "evidence = dict(Toothache=True)\n",
    "P_Cavity_Toothache = enumerate_joint_ask(query_variable, evidence, full_joint)\n",
    "(P_Cavity_Toothache[True], P_Cavity_Toothache[False])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <font color=dark-magenta>TASK:</font> You can verify that the first value is the same as we obtained earlier by \"manual\" calculation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Q5.3.9 [optional] sanity check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <font color=dark-magenta>TASK:</font> For completeness - or a sanity check - compute (using Python) the value for $P(Cavity=True | Toothache=True)$ using the expression for Bayes rule derived in Q5.3.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q5.4  Bayesian Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=red>__Warning:__ This part is more open-ended that 5.0-5.3. While ther are suggestions for tasks it up to you to explore the details of the code and applicaitons. </font>\n",
    "\n",
    "A Bayesian network is a representation of the joint probability distribution encoding a collection of conditional independence statements. This represent our __knowledge__ about these variables based on defined / observed probability distribution.\n",
    "\n",
    "A Bayes Network is implemented as the class **BayesNet**. It consisits of a collection of nodes implemented by the class **BayesNode**. The implementation in the above mentioned classes focuses only on boolean variables. Each node is associated with a variable and it contains a **conditional probabilty table (cpt)**. The **cpt** represents the probability distribution of the variable conditioned on its parents $P(X_i | parents(X_i))$.\n",
    "\n",
    "Let us dive into the **BayesNode** implementation (note it is NOT critical that you understand teh details!)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class BayesNode:\n",
    "    \"\"\"A conditional probability distribution for a boolean variable,\n",
    "    P(X | parents). Part of a BayesNet.\"\"\"\n",
    "\n",
    "    def __init__(self, X, parents, cpt):\n",
    "        \"\"\"X is a variable name, and parents a sequence of variable\n",
    "        names or a space-separated string.  cpt, the conditional\n",
    "        probability table, takes one of these forms:\n",
    "\n",
    "        * A number, the unconditional probability P(X=true). You can\n",
    "          use this form when there are no parents.\n",
    "\n",
    "        * A dict {v: p, ...}, the conditional probability distribution\n",
    "          P(X=true | parent=v) = p. When there's just one parent.\n",
    "\n",
    "        * A dict {(v1, v2, ...): p, ...}, the distribution P(X=true |\n",
    "          parent1=v1, parent2=v2, ...) = p. Each key must have as many\n",
    "          values as there are parents. You can use this form always;\n",
    "          the first two are just conveniences.\n",
    "\n",
    "        In all cases the probability of X being false is left implicit,\n",
    "        since it follows from P(X=true).\n",
    "\n",
    "        >>> X = BayesNode('X', '', 0.2)\n",
    "        >>> Y = BayesNode('Y', 'P', {T: 0.2, F: 0.7})\n",
    "        >>> Z = BayesNode('Z', 'P Q',\n",
    "        ...    {(T, T): 0.2, (T, F): 0.3, (F, T): 0.5, (F, F): 0.7})\n",
    "        \"\"\"\n",
    "        if isinstance(parents, str):\n",
    "            parents = parents.split()\n",
    "\n",
    "        # We store the table always in the third form above.\n",
    "        if isinstance(cpt, (float, int)):  # no parents, 0-tuple\n",
    "            cpt = {(): cpt}\n",
    "        elif isinstance(cpt, dict):\n",
    "            # one parent, 1-tuple\n",
    "            if cpt and isinstance(list(cpt.keys())[0], bool):\n",
    "                cpt = {(v,): p for v, p in cpt.items()}\n",
    "\n",
    "        assert isinstance(cpt, dict)\n",
    "        for vs, p in cpt.items():\n",
    "            assert isinstance(vs, tuple) and len(vs) == len(parents)\n",
    "            assert all(isinstance(v, bool) for v in vs)\n",
    "            assert 0 <= p <= 1\n",
    "\n",
    "        self.variable = X\n",
    "        self.parents = parents\n",
    "        self.cpt = cpt\n",
    "        self.children = []\n",
    "\n",
    "    def p(self, value, event):\n",
    "        \"\"\"Return the conditional probability\n",
    "        P(X=value | parents=parent_values), where parent_values\n",
    "        are the values of parents in event. (event must assign each\n",
    "        parent a value.)\n",
    "        >>> bn = BayesNode('X', 'Burglary', {T: 0.2, F: 0.625})\n",
    "        >>> bn.p(False, {'Burglary': False, 'Earthquake': True})\n",
    "        0.375\"\"\"\n",
    "        assert isinstance(value, bool)\n",
    "        ptrue = self.cpt[event_values(event, self.parents)]\n",
    "        return ptrue if value else 1 - ptrue\n",
    "\n",
    "    def sample(self, event):\n",
    "        \"\"\"Sample from the distribution for this variable conditioned\n",
    "        on event's values for parent_variables. That is, return True/False\n",
    "        at random according with the conditional probability given the\n",
    "        parents.\"\"\"\n",
    "        return probability(self.p(True, event))\n",
    "\n",
    "    def __repr__(self):\n",
    "        return repr((self.variable, ' '.join(self.parents)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The constructor takes in the name of **variable**, **parents** and **cpt**. Here **variable** is a the name of the variable like 'Earthquake'. **parents** should a list or space separate string with variable names of parents. The conditional probability table is a dict {(v1, v2, ...): p, ...}, the distribution P(X=true | parent1=v1, parent2=v2, ...) = p. Here the keys are combination of boolean values that the parents take. The length and order of the values in keys should be same as the supplied **parent** list/string. In all cases the probability of X being false is left implicit, since it follows from P(X=true).\n",
    "\n",
    "In the example below we implement the network shown in **AIMA Figure 14.3** of the book :\n",
    "\n",
    "<img src=\"./resources/bayesnet.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To represent knowlegde in this domain we define a function BayesNet which exploits the BayesNode in defining a full network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BayesNet:\n",
    "    \"\"\"Bayesian network containing only boolean-variable nodes.\"\"\"\n",
    "\n",
    "    def __init__(self, node_specs=[]):\n",
    "        \"\"\"Nodes must be ordered with parents before children.\"\"\"\n",
    "        self.nodes = []\n",
    "        self.variables = []\n",
    "        for node_spec in node_specs:\n",
    "            self.add(node_spec)\n",
    "\n",
    "    def add(self, node_spec):\n",
    "        \"\"\"Add a node to the net. Its parents must already be in the\n",
    "        net, and its variable must not.\"\"\"\n",
    "        node = BayesNode(*node_spec)\n",
    "        assert node.variable not in self.variables\n",
    "        assert all((parent in self.variables) for parent in node.parents)\n",
    "        self.nodes.append(node)\n",
    "        self.variables.append(node.variable)\n",
    "        for parent in node.parents:\n",
    "            self.variable_node(parent).children.append(node)\n",
    "\n",
    "    def variable_node(self, var):\n",
    "        \"\"\"Return the node for the variable named var.\n",
    "        >>> burglary.variable_node('Burglary').variable\n",
    "        'Burglary'\"\"\"\n",
    "        for n in self.nodes:\n",
    "            if n.variable == var:\n",
    "                return n\n",
    "        raise Exception(\"No such variable: {}\".format(var))\n",
    "\n",
    "    def variable_values(self, var):\n",
    "        \"\"\"Return the domain of var.\"\"\"\n",
    "        return [True, False]\n",
    "\n",
    "    def __repr__(self):\n",
    "        return 'BayesNet({0!r})'.format(self.nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "#### Q5.4.1 Define a BayeNet for the Burglary example\n",
    "\n",
    "We will now define the network for your problem:\n",
    "\n",
    "\n",
    "* <font color=dark-magenta>TASK:</font> Complete the specificaiton below (replace ? with their crrect values from Fig 14.2 in the book)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T, F = True, False\n",
    "\n",
    "burglary = BayesNet([\n",
    "    ('Burglary', '', 0.001),\n",
    "    ('Earthquake', '', ?),\n",
    "    ('Alarm', 'Burglary Earthquake',\n",
    "     {(T, T): 0.95, (T, F): ?, (F, T): 0.29, (F, F): 0.001}),\n",
    "    ('JohnCalls', 'Alarm', {T: 0.90, F: 0.05}),\n",
    "    ('MaryCalls', 'Alarm', {T: 0.70, F: ?})\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**BayesNet** method **variable_node** allows to reach **BayesNode** instances inside a Bayes Net. It is possible to extract (and modify the cpt using this method e.g."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "burglary.variable_node('Alarm').cpt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q5.4.1 Compactness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Bayes Network is typically a more compact representation of the full joint distribution and like full joint distributions allows us to do inference i.e. answer questions about probability distributions of random variables given some evidence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <font color=dark-magenta>TASK:</font> Explain in your own words why Bayes Networks are **typically** a more compact representation that the full joint distrbution ? In what case is it not more compact ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Q5.4.2 Inference by Enumeration (tutorial)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We apply techniques similar to those used for **enumerate_joint_ask** and **enumerate_joint** to draw inference from Bayesian Networks. **enumeration_ask** and **enumerate_all** implement the algorithm described in **Figure 14.9** of the book."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enumerate_all(variables, e, bn):\n",
    "    \"\"\"Return the sum of those entries in P(variables | e{others})\n",
    "    consistent with e, where P is the joint distribution represented\n",
    "    by bn, and e{others} means e restricted to bn's other variables\n",
    "    (the ones other than variables). Parents must precede children in variables.\"\"\"\n",
    "    if not variables:\n",
    "        return 1.0\n",
    "    Y, rest = variables[0], variables[1:]\n",
    "    Ynode = bn.variable_node(Y)\n",
    "    if Y in e:\n",
    "        return Ynode.p(e[Y], e) * enumerate_all(rest, e, bn)\n",
    "    else:\n",
    "        return sum(Ynode.p(y, e) * enumerate_all(rest, extend(e, Y, y), bn)\n",
    "                   for y in bn.variable_values(Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**enumerate__all** recursively evaluates a general form of the **Equation 14.4** in the book.\n",
    "\n",
    "$${P}(X | {e}) = α {P}(X, {e}) = α \\sum_{y} {P}(X, {e}, {y})$$ \n",
    "\n",
    "such that $P(X, e, y)$ is written in the form of product of conditional probabilities **P(variable | parents(variable))** from the Bayesian Network.\n",
    "\n",
    "**enumeration_ask** calls **enumerate_all** on each value of query variable $X$ and finally normalizes them. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enumeration_ask(X, e, bn):\n",
    "    u\"\"\"Return the conditional probability distribution of variable X\n",
    "    given evidence e, from BayesNet bn. [Figure 14.9]\n",
    "    >>> enumeration_ask('Burglary', dict(JohnCalls=T, MaryCalls=T), burglary\n",
    "    ...  ).show_approx()\n",
    "    'False: 0.716, True: 0.284'\"\"\"\n",
    "    assert X not in e, u\"Query variable must be distinct from evidence\"\n",
    "    Q = ProbDist(X)\n",
    "    for xi in bn.variable_values(X):\n",
    "        Q[xi] = enumerate_all(bn.variables, extend(e, X, xi), bn)\n",
    "    return Q.normalize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us solve the problem of finding out $P(Burglary=True | JohnCalls=True, MaryCalls=True)$ using the **burglary** network. **enumeration_ask** takes three arguments $X$ = variable name, $e$ = Evidence (in form a dict like previously explained), **bn** = The Bayes Net to do inference on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P_B_JM = enumeration_ask('Burglary', {'JohnCalls': True, 'MaryCalls': True}, burglary)\n",
    "(P_B_JM[True],P_B_JM[False])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Q5.4.4 Manual inference in the Bayesian network\n",
    "* <font color=dark-magenta>TASK:</font> Manually (without Python) compute the distrbution for $P(Burglary\\,,\\,MaryCalls\\,|\\,JohnCalls)$ ) (you don't need to insert the nummerical expressions; only the relevant conditional distrbutions)\n",
    "\n",
    "Hint: you will often be asked to do something similar in the exam."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Q5.4.4 Inference in the Bayesian network (using Python)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <font color=dark-magenta>TASKS:</font>  Use `enumeration_ask` to:\n",
    "    * Compute $P(Burglary\\,|\\,Alarm)$\n",
    "    * Compute $P(JohnCalls\\,|\\,MaryCalls)$\n",
    "    * Compute $P(JohnCalls)$\n",
    "    * Compute $P(Burglary\\,|\\,JohnCalls)$\n",
    "    * Compute $P(MaryCalls\\,|\\,Alarm, JohnCalls)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q5.5 Your Own Bayes Net [optional]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* It is highly recommended that you try to define you own network (e.g. using an example from the book or online) and perform inference using different methods (especially the exact ones). The code provided in this notebook allows you to use Boolean variables only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}